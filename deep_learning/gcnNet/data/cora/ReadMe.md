@[TOC](文章目录)

---

# 前言

---
最近看了这个GCN图神经网络的代码和论文，对这个神经网络也算是有一些了解，这里做一个阶段性的总结，以便后续回忆起来更加方便。

# 一、GCN是什么？

1、（graph convolution network）图卷积神经网络,是2016年诞生，在顶级会议（ICLR）上面发表，后面便兴起了图神经网络。 2、CNN，RNN等神经网络，对图结构的数据，一直都没有取得良好的效果，GCN做到了。
3、我想其实也是可以延着图神经网络这条线，一直学习下去的，毕竟图神经网络可以很好的提取相关的特征啊。

# 二、公式，原理等

公式：
![img.png](img.png)

`参数说明`

- A波浪：A+I，I是单位矩阵
- D波浪：是A波浪的度矩阵
- H是每一层的特征，对于输入层，H就是X
- σ是非线性激活函数
- W是参数矩阵

# 三、代码部分的学习

1、代码目录结构：

- layers.py:封装了GraphConvolution,主要是对参数进行设置，包括weight参数，bias参数的设置定义等


- utils.py:提供了数据初始化，onehot编码，将scipy稀疏矩阵转化为torch的稀疏矩阵，归一化稀疏矩阵，以及计算准确度的函数  
  详细介绍：
    - one_hot():onehot编码，这里使用了一个比较巧妙的方法：先是创建了一个dict的for循环，然后使用map(a,b)函数,a:前面定义的字典写法，b:
      label数据，这样就把整个数据切换为了onehot编码。identity():用于n*n的单位矩阵(主对角线素全为1，其余全为0的矩阵)。到时候可以学习一下它的写法。
    - load_data():
      这个方法中包含了很多关于矩阵数据处理的方法：获取特征的标签；创建图数据；导入edges数据；构建邻接矩阵数据；建立对称邻接矩阵；计算转置矩阵，将有向图转成无向图；使用自行定义的归一化方法，进行归一化；以及将numpy数据转化为torch(
      张量数据)
    - sparse_mx_to_torch_sparse_tensor():这里是将scipy稀疏矩阵转化为torch稀疏矩阵：from_numpy():将numpy.ndarray转化为pytorch的tensor,
    - normalize():行归一化稀疏矩阵。这里有几个方法：isinf():判断无穷大值；diags():构造对角矩阵；dot():是点乘函数，即每个对应的点进行相乘，然后相加。
- model.py:搭建的神经网络，以及一个正向传播的方法
- train.py:这里主要就是训练模型的  
  · 用创建的模型，训练数据，这里前面是定义了一个模型的，  
  · 运行模型，输入参数，  
  · 损失函数定义  
  · 计算精确度
- 数据集  
  · cora.site:两列数据，即表示两个对应节点之间，有连接关系 · cora.content：最后一列是标签，前面是特征数据

# 总结

    所以，我看了这个代码之后，最直观的是学习了几个关于矩阵处理的方法么？里面的GCN卷积层似乎都没有学习到，